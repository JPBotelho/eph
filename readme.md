# ephemeral-prometheus

Run PromQL queries without a running Prometheus instance.

**ephemeral-prometheus** is a CLI tool that lets you load metrics from a file and run [PromQL](https://prometheus.io/docs/prometheus/latest/querying/basics/) queries against them â€” no Prometheus server required.

It pairs with an **ingester** that supports pull and push-based metric ingestion, uploading them to an S3-compatible blob storage in a format the CLI can understand.

---
## Motivation
If you are generating metrics from self-contained, ephemeral workloads, you might want to store those in blob storage rather than your 'main' prometheus / mimir backend, to avoid cluttering. 

This tool allows you to run queries on those files.

## Supported formats

Currently, Prometheus text format **with timestamps** is supported. The ingester supports this format. While scraping, it appends the timestamp to targets that do not expose it.

Example:
```
# HELP go_gc_cycles_automatic_gc_cycles_total Count of completed GC cycles generated by the Go runtime. Sourced from /gc/cycles/automatic:gc-cycles.
# TYPE go_gc_cycles_automatic_gc_cycles_total counter
go_gc_cycles_automatic_gc_cycles_total 209 1754154517000
# HELP go_gc_cycles_automatic_gc_cycles_total Count of completed GC cycles generated by the Go runtime. Sourced from /gc/cycles/automatic:gc-cycles.
# TYPE go_gc_cycles_automatic_gc_cycles_total counter
go_gc_cycles_automatic_gc_cycles_total 20900 1754154517001
```

Although the Prometheus parser complains about having duplicate comments, the CLI strips comments before processing. The reason for this is so we can have a single file with several scrapes (append to file instead of making new one).


## How it works
The **ingester** can be configured:
 - **to scrape** a target serving Prometheus text exposition format (the usual /metrics). It will append the current timestamp if not present, and append it to the current job's file. When the **job finishes** it will upload the file to the configured destination.
 - as a **remote write** target. 

The **cli**:
 - starts a local TSDB (similar to promtool test)
 - fetches the file, parsing based on the format and loading it into TSDB
 - runs PromQl queries using Prometheus' engine.

So very little is done on the Querying side, it's all prometheus - this tool just gives you a nicer interface.

## Future work
Load data from a grafana csv file.
Run inside a cloudflare worker (both ingester and querier).

## Installation

```bash
git clone https://github.com/yourusername/ephemeral-prometheus.git
cd ephemeral-prometheus
go build -o ephemeral-prometheus .
